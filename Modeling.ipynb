{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Packages",
   "id": "9ce91115b746a65b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T22:40:27.588877Z",
     "start_time": "2024-11-15T22:40:25.837245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Logistic Regression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Random Forest \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#XGBoost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading in the Data",
   "id": "109bcbb891301062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T22:40:39.885110Z",
     "start_time": "2024-11-15T22:40:34.810819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/filtered_data.csv')\n",
    "# df = pd.read_csv('data/filtered_data_wider.csv')"
   ],
   "id": "a06cb2942a9c67c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T22:40:43.259225Z",
     "start_time": "2024-11-15T22:40:39.894781Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "99a1d0bd77654387",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Unnamed: 0                      gameid         GameDate  ab  pitchnum  \\\n",
       "0                8  2021/04/17/nynmlb-colmlb-2  4/16/2021 20:33  32         4   \n",
       "1               11  2021/04/17/nynmlb-colmlb-2  4/16/2021 20:33  33         3   \n",
       "2               30  2021/04/21/pitmlb-detmlb-2  4/21/2021 17:40  45         4   \n",
       "3               33  2021/04/25/arimlb-atlmlb-1  4/25/2021 12:20  12         4   \n",
       "4               38  2021/04/25/arimlb-atlmlb-1  4/25/2021 12:20  12         3   \n",
       "...            ...                         ...              ...  ..       ...   \n",
       "187400      717544  2023/08/30/clemlb-minmlb-1  8/30/2023 17:10  42         5   \n",
       "187401      717550  2023/08/30/atlmlb-colmlb-1   8/31/2023 0:40  37         3   \n",
       "187402      717573  2023/08/30/arimlb-lanmlb-1   8/31/2023 2:10  34         5   \n",
       "187403      717576  2023/09/02/pitmlb-slnmlb-1   9/2/2023 23:15  54         4   \n",
       "187404      717581  2023/09/02/nyamlb-houmlb-1   9/2/2023 23:10  57         3   \n",
       "\n",
       "        inning  teambat  balls  strikes  outs  ... inducedvertbreak  \\\n",
       "0          4.0        1    1.0      2.0   1.0  ...         5.260902   \n",
       "1          4.0        1    0.0      2.0   2.0  ...         6.102530   \n",
       "2          6.0        1    1.0      2.0   0.0  ...        -3.835304   \n",
       "3          2.0        0    1.0      2.0   1.0  ...         2.129060   \n",
       "4          2.0        0    0.0      2.0   1.0  ...        13.794325   \n",
       "...        ...      ...    ...      ...   ...  ...              ...   \n",
       "187400     6.0        1    1.0      2.0   0.0  ...        -3.927244   \n",
       "187401     5.0        1    0.0      2.0   0.0  ...         4.477882   \n",
       "187402     4.0        1    1.0      2.0   0.0  ...        14.275191   \n",
       "187403     7.0        0    1.0      2.0   0.0  ...        14.733393   \n",
       "187404     7.0        0    0.0      2.0   1.0  ...        17.788908   \n",
       "\n",
       "       platelocside platelocheight hometeam_id                 Home  \\\n",
       "0         -0.114617       2.546066         115     Colorado Rockies   \n",
       "1          0.880186       1.700091         115     Colorado Rockies   \n",
       "2         -0.239593       2.348037         116       Detroit Tigers   \n",
       "3          1.028702       2.689594         144       Atlanta Braves   \n",
       "4          1.286732       2.807080         144       Atlanta Braves   \n",
       "...             ...            ...         ...                  ...   \n",
       "187400    -0.362439       1.593713         142      Minnesota Twins   \n",
       "187401     0.436818       1.588252         115     Colorado Rockies   \n",
       "187402     0.586442       1.884596         119  Los Angeles Dodgers   \n",
       "187403    -0.807034       4.470551         138  St. Louis Cardinals   \n",
       "187404    -1.050967       2.320313         117       Houston Astros   \n",
       "\n",
       "       awayteam_id               Visitor venue_id        venue_name  \\\n",
       "0              121         New York Mets       19       Coors Field   \n",
       "1              121         New York Mets       19       Coors Field   \n",
       "2              134    Pittsburgh Pirates     2394     Comerica Park   \n",
       "3              109  Arizona Diamondbacks     4705       Truist Park   \n",
       "4              109  Arizona Diamondbacks     4705       Truist Park   \n",
       "...            ...                   ...      ...               ...   \n",
       "187400         114   Cleveland Guardians     3312      Target Field   \n",
       "187401         144        Atlanta Braves       19       Coors Field   \n",
       "187402         109  Arizona Diamondbacks       22    Dodger Stadium   \n",
       "187403         134    Pittsburgh Pirates     2889     Busch Stadium   \n",
       "187404         147      New York Yankees     2392  Minute Maid Park   \n",
       "\n",
       "        strikeout_binary  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "187400                 0  \n",
       "187401                 0  \n",
       "187402                 0  \n",
       "187403                 0  \n",
       "187404                 0  \n",
       "\n",
       "[187405 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gameid</th>\n",
       "      <th>GameDate</th>\n",
       "      <th>ab</th>\n",
       "      <th>pitchnum</th>\n",
       "      <th>inning</th>\n",
       "      <th>teambat</th>\n",
       "      <th>balls</th>\n",
       "      <th>strikes</th>\n",
       "      <th>outs</th>\n",
       "      <th>...</th>\n",
       "      <th>inducedvertbreak</th>\n",
       "      <th>platelocside</th>\n",
       "      <th>platelocheight</th>\n",
       "      <th>hometeam_id</th>\n",
       "      <th>Home</th>\n",
       "      <th>awayteam_id</th>\n",
       "      <th>Visitor</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>strikeout_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2021/04/17/nynmlb-colmlb-2</td>\n",
       "      <td>4/16/2021 20:33</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.260902</td>\n",
       "      <td>-0.114617</td>\n",
       "      <td>2.546066</td>\n",
       "      <td>115</td>\n",
       "      <td>Colorado Rockies</td>\n",
       "      <td>121</td>\n",
       "      <td>New York Mets</td>\n",
       "      <td>19</td>\n",
       "      <td>Coors Field</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2021/04/17/nynmlb-colmlb-2</td>\n",
       "      <td>4/16/2021 20:33</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.102530</td>\n",
       "      <td>0.880186</td>\n",
       "      <td>1.700091</td>\n",
       "      <td>115</td>\n",
       "      <td>Colorado Rockies</td>\n",
       "      <td>121</td>\n",
       "      <td>New York Mets</td>\n",
       "      <td>19</td>\n",
       "      <td>Coors Field</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2021/04/21/pitmlb-detmlb-2</td>\n",
       "      <td>4/21/2021 17:40</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.835304</td>\n",
       "      <td>-0.239593</td>\n",
       "      <td>2.348037</td>\n",
       "      <td>116</td>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>134</td>\n",
       "      <td>Pittsburgh Pirates</td>\n",
       "      <td>2394</td>\n",
       "      <td>Comerica Park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>2021/04/25/arimlb-atlmlb-1</td>\n",
       "      <td>4/25/2021 12:20</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.129060</td>\n",
       "      <td>1.028702</td>\n",
       "      <td>2.689594</td>\n",
       "      <td>144</td>\n",
       "      <td>Atlanta Braves</td>\n",
       "      <td>109</td>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>4705</td>\n",
       "      <td>Truist Park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>2021/04/25/arimlb-atlmlb-1</td>\n",
       "      <td>4/25/2021 12:20</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.794325</td>\n",
       "      <td>1.286732</td>\n",
       "      <td>2.807080</td>\n",
       "      <td>144</td>\n",
       "      <td>Atlanta Braves</td>\n",
       "      <td>109</td>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>4705</td>\n",
       "      <td>Truist Park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187400</th>\n",
       "      <td>717544</td>\n",
       "      <td>2023/08/30/clemlb-minmlb-1</td>\n",
       "      <td>8/30/2023 17:10</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.927244</td>\n",
       "      <td>-0.362439</td>\n",
       "      <td>1.593713</td>\n",
       "      <td>142</td>\n",
       "      <td>Minnesota Twins</td>\n",
       "      <td>114</td>\n",
       "      <td>Cleveland Guardians</td>\n",
       "      <td>3312</td>\n",
       "      <td>Target Field</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187401</th>\n",
       "      <td>717550</td>\n",
       "      <td>2023/08/30/atlmlb-colmlb-1</td>\n",
       "      <td>8/31/2023 0:40</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.477882</td>\n",
       "      <td>0.436818</td>\n",
       "      <td>1.588252</td>\n",
       "      <td>115</td>\n",
       "      <td>Colorado Rockies</td>\n",
       "      <td>144</td>\n",
       "      <td>Atlanta Braves</td>\n",
       "      <td>19</td>\n",
       "      <td>Coors Field</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187402</th>\n",
       "      <td>717573</td>\n",
       "      <td>2023/08/30/arimlb-lanmlb-1</td>\n",
       "      <td>8/31/2023 2:10</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.275191</td>\n",
       "      <td>0.586442</td>\n",
       "      <td>1.884596</td>\n",
       "      <td>119</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>109</td>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>22</td>\n",
       "      <td>Dodger Stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187403</th>\n",
       "      <td>717576</td>\n",
       "      <td>2023/09/02/pitmlb-slnmlb-1</td>\n",
       "      <td>9/2/2023 23:15</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.733393</td>\n",
       "      <td>-0.807034</td>\n",
       "      <td>4.470551</td>\n",
       "      <td>138</td>\n",
       "      <td>St. Louis Cardinals</td>\n",
       "      <td>134</td>\n",
       "      <td>Pittsburgh Pirates</td>\n",
       "      <td>2889</td>\n",
       "      <td>Busch Stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187404</th>\n",
       "      <td>717581</td>\n",
       "      <td>2023/09/02/nyamlb-houmlb-1</td>\n",
       "      <td>9/2/2023 23:10</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.788908</td>\n",
       "      <td>-1.050967</td>\n",
       "      <td>2.320313</td>\n",
       "      <td>117</td>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>147</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>2392</td>\n",
       "      <td>Minute Maid Park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187405 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filtering the DataFrame",
   "id": "6a46e554a30dc21e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T22:40:44.098138Z",
     "start_time": "2024-11-15T22:40:43.327581Z"
    }
   },
   "cell_type": "code",
   "source": "data = df[[\"pitcher\",\"pitchname\", \"pitchresult\", \"eventtype\",\"spinrate\", \"relspeed\", \"horzbreak\", \"inducedvertbreak\", \"platelocside\", \"platelocheight\", \"strikeout_binary\"]].copy()",
   "id": "80ebd5f8379139b1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T22:40:45.831728Z",
     "start_time": "2024-11-15T22:40:45.608750Z"
    }
   },
   "cell_type": "code",
   "source": "data = data[data['pitchname'] == 'FF'].copy()",
   "id": "4b00f853aebe3874",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fc980f6a7f46b227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data['eventtype'].unique()",
   "id": "6883f4e939dca2e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = data[~data['eventtype'].isin(['field_out'])]\n",
    "data"
   ],
   "id": "5fd33d9d395825dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# IF YOU UNCOMMENT, ONLY STRIKEOUTS AND BALLS",
   "id": "a2b5ef3495d237a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter the DataFrame to only include the specified event types\n",
    "# data = data[data['eventtype'].isin(['strikeout', 'strikeout_double_play', 'ball', 'passed ball'])]\n",
    "# # Define the list of events to remove\n",
    "# irrelevant_events = [\n",
    "#     'field_out', 'grounded_into_double_play', 'double_play', 'triple_play',\n",
    "#     'field_error', 'defensive_indiff', 'passed_ball', 'wild_pitch', 'catcher_interf'\n",
    "# ]\n",
    "# \n",
    "# # Filter out rows where 'eventtype' matches any of the specified events or contains specified patterns\n",
    "# data = data[\n",
    "#     ~data['eventtype'].isin(irrelevant_events) & \n",
    "#     ~data['eventtype'].str.contains('caught_stealing') & \n",
    "#     ~data['eventtype'].str.contains('stolen_base') & \n",
    "#     ~data['eventtype'].str.contains('pickoff')\n",
    "# ]\n",
    "# \n",
    "# data = data[~data['eventtype'].str.contains('pickoff')]\n",
    "# \n",
    "# # Display the filtered DataFrame\n",
    "# data"
   ],
   "id": "736741646bbe5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data['eventtype'].value_counts()",
   "id": "52ac244616260660",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data['eventtype'].unique()",
   "id": "6c3ddc7f0e59321d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Looking at outliers",
   "id": "feae9e1ea4119f8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_features = data.select_dtypes(include=[np.number]).columns\n",
    "numerical_data = data[numerical_features]\n",
    "\n",
    "# Plot boxplots for numerical features to visualize outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "numerical_data.boxplot(rot=90)\n",
    "plt.title('Boxplot of Numerical Features to Identify Outliers')\n",
    "plt.show()"
   ],
   "id": "6fb1c8dfa86fb5bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select numerical features\n",
    "numerical_features = data.select_dtypes(include=[np.number]).columns\n",
    "numerical_data = data[numerical_features]\n",
    "numerical_data = data[[col for col in numerical_features if col != 'spinrate']]\n",
    "\n",
    "# Plot boxplots for numerical features to visualize outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "numerical_data.boxplot(rot=90)\n",
    "plt.title('Boxplot of Numerical Features to Identify Outliers')\n",
    "plt.show()"
   ],
   "id": "731a8e1bea3684d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# numerical_data = data[numerical_features]\n",
    "# \n",
    "# # Function to remove outliers using the IQR method\n",
    "# def remove_outliers_iqr(data, columns, threshold=100):\n",
    "#     cleaned_data = data.copy()\n",
    "#     for column in columns:\n",
    "#         Q1 = cleaned_data[column].quantile(0.25)\n",
    "#         Q3 = cleaned_data[column].quantile(0.75)\n",
    "#         IQR = Q3 - Q1\n",
    "#         lower_bound = Q1 - threshold * IQR\n",
    "#         upper_bound = Q3 + threshold * IQR\n",
    "#         # Remove rows with outliers\n",
    "#         cleaned_data = cleaned_data[(cleaned_data[column] >= lower_bound) & (cleaned_data[column] <= upper_bound)]\n",
    "#     return cleaned_data\n",
    "# \n",
    "# # Remove outliers from the numerical features\n",
    "# cleaned_data = remove_outliers_iqr(numerical_data, numerical_features)\n",
    "# \n",
    "# # Display the shape of the dataset before and after removing outliers\n",
    "# original_shape = numerical_data.shape\n",
    "# cleaned_shape = cleaned_data.shape\n",
    "# \n",
    "# original_shape, cleaned_shape"
   ],
   "id": "efc8500763d779e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to remove outliers using the IQR method for a given dataset\n",
    "def remove_outliers_iqr_classwise(data, columns, threshold=1.5):\n",
    "    cleaned_data = data.copy()\n",
    "    for column in columns:\n",
    "        Q1 = cleaned_data[column].quantile(0.25)\n",
    "        Q3 = cleaned_data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        # Remove rows with outliers\n",
    "        cleaned_data = cleaned_data[(cleaned_data[column] >= lower_bound) & (cleaned_data[column] <= upper_bound)]\n",
    "    return cleaned_data\n",
    "\n",
    "# Separate the data into classes\n",
    "strikeout_data = data[data['strikeout_binary'] == 1]\n",
    "non_strikeout_data = data[data['strikeout_binary'] == 0]\n",
    "\n",
    "# Remove outliers separately for each class\n",
    "strikeout_data_cleaned = remove_outliers_iqr_classwise(strikeout_data, numerical_features)\n",
    "non_strikeout_data_cleaned = remove_outliers_iqr_classwise(non_strikeout_data, numerical_features)\n",
    "\n",
    "# Concatenate the cleaned data from both classes\n",
    "cleaned_data_classwise = pd.concat([strikeout_data_cleaned, non_strikeout_data_cleaned])\n",
    "\n",
    "# Check the distribution of the target variable in the cleaned dataset\n",
    "strikeout_distribution_classwise = cleaned_data_classwise['strikeout_binary'].value_counts()\n",
    "strikeout_distribution_classwise\n"
   ],
   "id": "b0dc2c657d21325f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Looking @ histograms of features in nonstrike/strike scenarios:\n",
    "- I don't think spinrate, release speed, or horz break on their own have meaningful differences\n",
    "- I'm going to try combining vertical break & release speed \n",
    "- I think platelocside and platelocheight are going to be the most important \n"
   ],
   "id": "44fea76c70548dc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot histograms of numerical features before and after outlier removal for non-strikeouts and strikeouts\n",
    "\n",
    "# Original strikeout and non-strikeout data\n",
    "original_strikeout_data = data[data['strikeout_binary'] == 1]\n",
    "original_non_strikeout_data = data[data['strikeout_binary'] == 0]\n",
    "\n",
    "# Features to visualize\n",
    "features_to_visualize = ['spinrate', 'relspeed', 'horzbreak', 'inducedvertbreak', 'platelocside', 'platelocheight']\n",
    "\n",
    "# Plot before and after for each feature\n",
    "fig, axes = plt.subplots(len(features_to_visualize), 2, figsize=(15, 25))\n",
    "fig.suptitle('Comparison of Feature Distributions Before and After Outlier Removal', fontsize=16, y=1.02)\n",
    "\n",
    "for i, feature in enumerate(features_to_visualize):\n",
    "    # Original data (non-strikeouts)\n",
    "    sns.histplot(original_non_strikeout_data[feature], bins=30, kde=True, color='blue', ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{feature} - Non-strikeouts (Original)')\n",
    "    axes[i, 0].set_xlabel('')\n",
    "\n",
    "    # Cleaned data (non-strikeouts)\n",
    "    sns.histplot(non_strikeout_data_cleaned[feature], bins=30, kde=True, color='green', ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'{feature} - Non-strikeouts (Cleaned)')\n",
    "    axes[i, 1].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for strikeouts\n",
    "fig, axes = plt.subplots(len(features_to_visualize), 2, figsize=(15, 25))\n",
    "fig.suptitle('Comparison of Feature Distributions Before and After Outlier Removal (Strikeouts)', fontsize=16, y=1.02)\n",
    "\n",
    "for i, feature in enumerate(features_to_visualize):\n",
    "    # Original data (strikeouts)\n",
    "    sns.histplot(original_strikeout_data[feature], bins=30, kde=True, color='red', ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{feature} - Strikeouts (Original)')\n",
    "    axes[i, 0].set_xlabel('')\n",
    "\n",
    "    # Cleaned data (strikeouts)\n",
    "    sns.histplot(strikeout_data_cleaned[feature], bins=30, kde=True, color='orange', ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'{feature} - Strikeouts (Cleaned)')\n",
    "    axes[i, 1].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "a73d186d00ce94b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Seaborn style for consistency and aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Define a color palette for strikeouts and non-strikeouts\n",
    "colors = {\"non_strikeouts\": \"#4C72B0\", \"strikeouts\": \"#C44E52\"}\n",
    "\n",
    "# Plot cleaned data for each feature (horizontal layout with larger plots and enhancements)\n",
    "fig, axes = plt.subplots(2, len(features_to_visualize), figsize=(30, 15))\n",
    "fig.suptitle('Comparison of Feature Distributions for Cleaned Data: Strikeouts vs. Non-Strikeouts', fontsize=24, y=1.02, weight='bold', color='#333333')\n",
    "\n",
    "for i, feature in enumerate(features_to_visualize):\n",
    "    # Determine the x-axis limits based on combined data for consistency\n",
    "    x_min = min(non_strikeout_data_cleaned[feature].min(), strikeout_data_cleaned[feature].min())\n",
    "    x_max = max(non_strikeout_data_cleaned[feature].max(), strikeout_data_cleaned[feature].max())\n",
    "\n",
    "    # Cleaned data (non-strikeouts)\n",
    "    sns.histplot(non_strikeout_data_cleaned[feature], bins=30, kde=True, color=colors[\"non_strikeouts\"], \n",
    "                 ax=axes[0, i], linewidth=1.5, alpha=0.8)\n",
    "    axes[0, i].set_title(f'Non-strikeouts ({feature})', fontsize=16, color='#4C72B0', weight='bold')\n",
    "    axes[0, i].set_xlabel('')\n",
    "    axes[0, i].set_ylabel('Count', fontsize=14)\n",
    "    axes[0, i].set_xlim(x_min, x_max)\n",
    "    axes[0, i].tick_params(axis='both', labelsize=12)\n",
    "    axes[0, i].grid(True, linestyle='--', linewidth=0.7, alpha=0.5)\n",
    "\n",
    "    # Cleaned data (strikeouts)\n",
    "    sns.histplot(strikeout_data_cleaned[feature], bins=30, kde=True, color=colors[\"strikeouts\"], \n",
    "                 ax=axes[1, i], linewidth=1.5, alpha=0.8)\n",
    "    axes[1, i].set_title(f'Strikeouts ({feature})', fontsize=16, color='#C44E52', weight='bold')\n",
    "    axes[1, i].set_xlabel('')\n",
    "    axes[1, i].set_ylabel('Count', fontsize=14)\n",
    "    axes[1, i].set_xlim(x_min, x_max)\n",
    "    axes[1, i].tick_params(axis='both', labelsize=12)\n",
    "    axes[1, i].grid(True, linestyle='--', linewidth=0.7, alpha=0.5)\n",
    "\n",
    "# Adjust the layout to give more space between plots\n",
    "plt.tight_layout(pad=5.0, w_pad=4.5, h_pad=4.0)\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.show()\n"
   ],
   "id": "990aa119b9bddd7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotly Plot!",
   "id": "a9f1ce0db5dc5404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d50d02f9a01b15bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a new variable that is relspeed and inducedvertbreak multiplied together\n",
    "cleaned_data_classwise['relspeed_inducedvertbreak'] = cleaned_data_classwise['relspeed'] * cleaned_data_classwise['inducedvertbreak']\n",
    "\n",
    "# Separate data into strikeouts and non-strikeouts\n",
    "strikeout_data = cleaned_data_classwise[cleaned_data_classwise['strikeout_binary'] == 1]\n",
    "non_strikeout_data = cleaned_data_classwise[cleaned_data_classwise['strikeout_binary'] == 0]\n",
    "\n",
    "# Plot the distribution of the new variable for strikeouts and non-strikeouts\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(strikeout_data['relspeed_inducedvertbreak'], bins=30, kde=True, color='red', label='Strikeouts')\n",
    "sns.histplot(non_strikeout_data['relspeed_inducedvertbreak'], bins=30, kde=True, color='green', label='Non-strikeouts')\n",
    "plt.title('Distribution of relspeed * inducedvertbreak for Strikeouts vs. Non-strikeouts')\n",
    "plt.xlabel('relspeed * inducedvertbreak')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "851a5ce84a51c935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "non_strikeout_data['eventtype'].unique()",
   "id": "a6681c02bfc6e83f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8b88ab45523bbb56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_columns = [\n",
    "        'spinrate', 'relspeed', 'horzbreak', 'inducedvertbreak', \n",
    "        'platelocside', 'platelocheight', 'relspeed_inducedvertbreak'\n",
    "    ]\n",
    "cleaned_data_classwise[feature_columns].corr()"
   ],
   "id": "e281059ecc052c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### If I want to keep just the interaction term:",
   "id": "a57dad19a3125027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count the appearances for each pitcher and filter out those with fewer than 50 appearances\n",
    "pitcher_appearances = cleaned_data_classwise['pitcher'].value_counts()\n",
    "pitchers_with_100_plus_appearances = pitcher_appearances[pitcher_appearances >= 100].index\n",
    "\n",
    "# Filter the dataframe to include only pitchers with 50 or more appearances\n",
    "cleaned_data_classwise = cleaned_data_classwise[cleaned_data_classwise['pitcher'].isin(pitchers_with_100_plus_appearances)]\n",
    "\n",
    "cleaned_data_classwise"
   ],
   "id": "77c68e918e513de7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ranking",
   "id": "129fa42ff26cad3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the number of 'strikeout' and 'ball' events for each pitcher\n",
    "strike_counts = cleaned_data_classwise[cleaned_data_classwise['eventtype'] == 'strikeout'].groupby('pitcher').size()\n",
    "ball_counts = cleaned_data_classwise[cleaned_data_classwise['eventtype'] == 'ball'].groupby('pitcher').size()\n",
    "\n",
    "# Combine these counts into a single DataFrame\n",
    "pitcher_stats = pd.DataFrame({'strikeouts': strike_counts, 'balls': ball_counts}).fillna(0)\n",
    "\n",
    "pitcher_stats = pitcher_stats[pitcher_stats['balls'] > 0]\n",
    "\n",
    "# Calculate the strike-to-ball ratio\n",
    "pitcher_stats['strike_to_ball_ratio'] = pitcher_stats['strikeouts'] / pitcher_stats['balls']\n",
    "\n",
    "# Get the top 10 pitchers by strike-to-ball ratio\n",
    "top_10_pitchers = pitcher_stats.sort_values(by='strike_to_ball_ratio', ascending=False).head(10)\n",
    "\n",
    "# Display the result\n",
    "top_10_pitchers"
   ],
   "id": "29d0adfd49a2daee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the top 10 pitchers by strike-to-ball ratio\n",
    "bottom_10_pitchers = pitcher_stats.sort_values(by='strike_to_ball_ratio', ascending=True).head(10)\n",
    "\n",
    "# Display the result\n",
    "bottom_10_pitchers"
   ],
   "id": "c2e7debf2335ab76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Add the new variable to the DataFrame\n",
    "# # cleaned_data_classwise['VelocityBreakProduct'] = cleaned_data_classwise['relspeed'] * cleaned_data_classwise['inducedvertbreak']\n",
    "# \n",
    "# # Remove the original 'relspeed' and 'inducedvertbreak' columns\n",
    "# cleaned_data_classwise = cleaned_data_classwise.drop(columns=['relspeed', 'inducedvertbreak'])\n",
    "# \n",
    "# # Display the first few rows of the updated DataFrame to confirm the changes\n",
    "cleaned_data_classwise.head()\n",
    "cleaned_data_classwise.to_csv('baseball_stuff.csv', index=False)"
   ],
   "id": "5ce1cadc16002c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### More feature engineering: Making a new col \n",
    "- this col averages each pitcher's average velocity and takes into acc on a pitch by pitch basis, how much the velo differs from the pitcher's regular speed"
   ],
   "id": "2120933e1873f1de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the pitcher's average release speed\n",
    "cleaned_data_classwise['average_relspeed'] = cleaned_data_classwise.groupby('pitcher')['relspeed'].transform('mean')\n",
    "\n",
    "# Calculate the difference between each pitch's release speed and the pitcher's average release speed\n",
    "cleaned_data_classwise['relspeed_diff'] = cleaned_data_classwise['relspeed'] - cleaned_data_classwise['average_relspeed']"
   ],
   "id": "aa40fa0c7d43bc3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separate data into strikeouts and non-strikeouts\n",
    "strikeout_data = cleaned_data_classwise[cleaned_data_classwise['strikeout_binary'] == 1]\n",
    "non_strikeout_data = cleaned_data_classwise[cleaned_data_classwise['strikeout_binary'] == 0]\n",
    "# Plot the distribution of the new variable for strikeouts and non-strikeouts\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(strikeout_data['relspeed'], bins=30, kde=True, color='red', label='Strikeouts')\n",
    "sns.histplot(non_strikeout_data['relspeed'], bins=30, kde=True, color='green', label='Non-strikeouts')\n",
    "plt.title('Distribution of Release Speed Difference for Strikeouts vs. Non-strikeouts')\n",
    "plt.xlabel('Release Speed Difference (relspeed - average_relspeed)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "4ad0a99dba56672b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_data_classwise",
   "id": "f4365019580a1242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic Regression",
   "id": "667d7fbc5f08b17c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Simplify pitchresult into broader categories\n",
    "def categorize_pitchresult(pitchresult):\n",
    "    if pitchresult in ['S', 'C']:  # Likely strike-related\n",
    "        return 'strike_related'\n",
    "    elif pitchresult in ['X', 'D', 'T', 'O']:  # In-play outcomes\n",
    "        return 'in_play'\n",
    "    elif pitchresult in ['B', 'W']:  # Balls and walks\n",
    "        return 'ball_related'\n",
    "    elif pitchresult == 'F':  # Foul\n",
    "        return 'foul'\n",
    "    else:  # Other miscellaneous outcomes\n",
    "        return 'other'\n",
    "\n",
    "# Apply categorization\n",
    "cleaned_data_classwise['pitchresult_category'] = cleaned_data_classwise['pitchresult'].apply(categorize_pitchresult)\n",
    "\n",
    "# One-hot encode the new categorical columns for logistic regression\n",
    "data_encoded = pd.get_dummies(cleaned_data_classwise, columns=['pitchresult_category'], drop_first=True)\n",
    "\n",
    "# Define the new feature set including the encoded pitchresult categories and original features\n",
    "feature_columns = [\n",
    "        'spinrate', 'average_relspeed', 'relspeed_diff', 'horzbreak', 'inducedvertbreak', \n",
    "        'platelocside', 'platelocheight', 'relspeed_inducedvertbreak'\n",
    "    ] # + [col for col in data_encoded.columns if 'pitchresult_category_' in col]\n",
    "\n",
    "# Separate features and target\n",
    "X = data_encoded[feature_columns]\n",
    "y = data_encoded['strikeout_binary']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train logistic regression model with class weights to handle imbalance\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "accuracy, precision, recall, roc_auc"
   ],
   "id": "d5f83750c15e4557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OverSampling",
   "id": "89898188c8b21a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = cleaned_data_classwise[[\n",
    "        'spinrate', 'average_relspeed', 'relspeed_diff', 'horzbreak', 'inducedvertbreak', \n",
    "        'platelocside', 'platelocheight', 'relspeed_inducedvertbreak'\n",
    "    ]]\n",
    "y = cleaned_data_classwise['strikeout_binary']  # assuming you have a column that indicates if the outcome was a strikeout (0 or 1)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train logistic regression model with class weights to handle imbalance\n",
    "log_reg = LogisticRegression(max_iter=1000,  class_weight={0: 1, 1: 0.94})\n",
    "# log_reg = LogisticRegression(max_iter=1000,  class_weight=\"balanced\")\n",
    "\n",
    "log_reg.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "accuracy, precision, recall, roc_auc"
   ],
   "id": "caa0e72dd52d237f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# X_train",
   "id": "1a23a9f22db993c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Looking at the Coefficients",
   "id": "f41c0fb8a81b4a14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the feature names and coefficients\n",
    "feature_names = X_train.columns\n",
    "coefficients = log_reg.coef_[0]\n",
    "\n",
    "# Create a DataFrame for easier interpretation\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "# Plot the coefficients for visual clarity\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Feature Importance: Logistic Regression Coefficients')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "feature_importance"
   ],
   "id": "f4b17c774cab9b93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest with NOTHING done",
   "id": "e934a7bff09dc56e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf_og = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf_og = precision_score(y_test, y_pred_rf)\n",
    "recall_rf_og = recall_score(y_test, y_pred_rf)\n",
    "roc_auc_rf_og = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "\n",
    "accuracy_rf_og, precision_rf_og, recall_rf_og, roc_auc_rf_og"
   ],
   "id": "9f60e749cefd888f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_rf_og = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'ROC AUC'],\n",
    "    'Value': [accuracy_rf_og, precision_rf_og, recall_rf_og, roc_auc_rf_og]\n",
    "}\n",
    "\n",
    "# Convert dictionary to a DataFrame\n",
    "accuracy_metrics_rf_df_og  = pd.DataFrame(metrics_rf_og)\n",
    "\n",
    "accuracy_metrics_rf_df_og"
   ],
   "id": "4ac798ad8300addc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest",
   "id": "d9eb080613adccd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest model with class weights to handle imbalance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight={0: 1, 1: 2}, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "\n",
    "accuracy_rf, precision_rf, recall_rf, roc_auc_rf"
   ],
   "id": "ae8df0d4ba889937",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_rf_1 = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'ROC AUC'],\n",
    "    'Value': [accuracy_rf, precision_rf, recall_rf, roc_auc_rf]\n",
    "}\n",
    "\n",
    "# Convert dictionary to a DataFrame\n",
    "accuracy_metrics_rf_df_1  = pd.DataFrame(metrics_rf_1)\n",
    "\n",
    "accuracy_metrics_rf_df_1"
   ],
   "id": "19b1bd59a21ed8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# \n",
    "# # Load the data\n",
    "# # df = pd.read_csv(file_path)\n",
    "# \n",
    "# # Simplify pitchresult into broader categories\n",
    "# df['pitchresult_category'] = df['pitchresult'].apply(categorize_pitchresult)\n",
    "# \n",
    "# # One-hot encode the new categorical columns for logistic regression\n",
    "# data_encoded = pd.get_dummies(df, columns=['pitchresult_category'], drop_first=True)\n",
    "# \n",
    "# # Define the new feature set including the encoded pitchresult categories and original features\n",
    "# feature_columns = [\n",
    "#     'spinrate', 'relspeed', 'horzbreak', 'inducedvertbreak', \n",
    "#     'platelocside', 'platelocheight'\n",
    "# ] + [col for col in data_encoded.columns if 'pitchresult_category_' in col]\n",
    "# \n",
    "# # Separate features and target\n",
    "# X = data_encoded[feature_columns]\n",
    "# y = data_encoded['strikeout_binary']\n",
    "# \n",
    "# # Oversample the minority class using SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "# \n",
    "# # Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "# \n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled_scaled, y_resampled, test_size=0.3, random_state=42)\n",
    "# \n",
    "# # Train Random Forest model with class weights to handle imbalance\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# \n",
    "# # Make predictions\n",
    "# y_pred_rf = rf_model.predict(X_test)\n",
    "# y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "# \n",
    "# # Evaluate the Random Forest model\n",
    "# accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "# precision_rf = precision_score(y_test, y_pred_rf, zero_division=1)\n",
    "# recall_rf = recall_score(y_test, y_pred_rf)\n",
    "# roc_auc_rf = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "# \n",
    "# accuracy_rf, precision_rf, recall_rf, roc_auc_rf"
   ],
   "id": "e1e4f41b29dcd3f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# X_train",
   "id": "3376b805e74c7cb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# X_resampled",
   "id": "316cdc627ada1e06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DownSampling with RandomForest",
   "id": "de8bad65bc0549b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the new feature set excluding the encoded pitchresult categories to avoid data leakage\n",
    "feature_columns = [\n",
    "        'spinrate', 'average_relspeed', 'relspeed_diff', 'horzbreak', 'inducedvertbreak', \n",
    "        'platelocside', 'platelocheight',  'relspeed_inducedvertbreak'\n",
    "    ]\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = data_encoded[feature_columns]\n",
    "y = data_encoded['strikeout_binary']\n",
    "\n",
    "# Concatenate features and target for resampling\n",
    "data_resampled = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "strikeout = data_resampled[data_resampled['strikeout_binary'] == 1]\n",
    "non_strikeout = data_resampled[data_resampled['strikeout_binary'] == 0]\n",
    "\n",
    "# Downsample majority class (non-strikeouts)\n",
    "non_strikeout_downsampled = resample(non_strikeout, \n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=len(strikeout),  # match minority class\n",
    "                                     random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "data_balanced = pd.concat([strikeout, non_strikeout_downsampled])\n",
    "\n",
    "# Separate features and target after resampling\n",
    "X_balanced = data_balanced.drop('strikeout_binary', axis=1)\n",
    "y_balanced = data_balanced['strikeout_binary']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_balanced_scaled = scaler.fit_transform(X_balanced)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced_scaled, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest model with class weights to handle imbalance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, zero_division=1)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "\n",
    "accuracy_rf, precision_rf, recall_rf, roc_auc_rf"
   ],
   "id": "9e0fcf7295905c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(classification_report(y_test, y_pred_rf))",
   "id": "1d53caf93cc5de40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_resampled",
   "id": "e9454efa0cdd4f86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Interaction between spinrate and relspeed\n",
    "data_encoded['spinrate_relspeed'] = data_encoded['spinrate'] * data_encoded['relspeed']\n",
    "\n",
    "# Movement Ratio between horizontal and vertical break\n",
    "data_encoded['movement_ratio'] = data_encoded['horzbreak'] / (data_encoded['inducedvertbreak'] + 1e-5)\n",
    "\n",
    "# Normalize plate location to capture if the pitch is at the edge of the strike zone\n",
    "data_encoded['is_edge_pitch'] = (\n",
    "    (data_encoded['platelocside'].abs() > 0.7) |  # Assuming a threshold for edge pitches\n",
    "    (data_encoded['platelocheight'] < 1.5) | \n",
    "    (data_encoded['platelocheight'] > 3.5)\n",
    ").astype(int)"
   ],
   "id": "6a21fef0e00d6169",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_encoded",
   "id": "3692fe187dc4cfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create new engineered features\n",
    "\n",
    "# Interaction between spinrate and relspeed\n",
    "data_encoded['spinrate_relspeed'] = data_encoded['spinrate'] * data_encoded['relspeed']\n",
    "\n",
    "# Movement Ratio between horizontal and vertical break\n",
    "data_encoded['movement_ratio'] = data_encoded['horzbreak'] / (data_encoded['inducedvertbreak'] + 1e-5)\n",
    "\n",
    "# Normalize plate location to capture if the pitch is at the edge of the strike zone\n",
    "data_encoded['is_edge_pitch'] = (\n",
    "    (data_encoded['platelocside'].abs() > 0.7) |  # Assuming a threshold for edge pitches\n",
    "    (data_encoded['platelocheight'] < 1.5) | \n",
    "    (data_encoded['platelocheight'] > 3.5)\n",
    ").astype(int)\n",
    "\n",
    "#Update the feature columns to include the new engineered features\n",
    "feature_columns = [ 'relspeed_inducedvertbreak', 'relspeed',\n",
    "        'spinrate', 'relspeed_diff', 'horzbreak', 'inducedvertbreak', \n",
    "        'platelocside', 'platelocheight'\n",
    "    ]\n",
    "\n",
    "\n",
    "# feature_columns = []\n",
    "# feature_columns = ['platelocside', 'platelocheight', 'relspeed_diff', 'horzbreak']\n",
    "\n",
    "# feature_columns = [\"spinrate\", \"relspeed\", \"horzbreak\", \"inducedvertbreak\", \"platelocheight\", \"platelocside\", \"is_edge_pitch\"]\n",
    "#, 'relspeed_inducedvertbreak'] # - prob gonna go with this one\n",
    "\n",
    "# feature_columns = ['average_relspeed','spinrate','platelocside', 'platelocheight', 'is_edge_pitch'] - might go with this one\n",
    "\n",
    "# Separate features and target\n",
    "X = data_encoded[feature_columns]\n",
    "y = data_encoded['strikeout_binary']\n",
    "\n",
    "# Concatenate features and target for resampling\n",
    "data_resampled = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "strikeout = data_resampled[data_resampled['strikeout_binary'] == 1]\n",
    "non_strikeout = data_resampled[data_resampled['strikeout_binary'] == 0]\n",
    "\n",
    "# Downsample majority class (non-strikeouts)\n",
    "non_strikeout_downsampled = resample(non_strikeout, \n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=len(strikeout),  # match minority class\n",
    "                                     random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "data_balanced = pd.concat([strikeout, non_strikeout_downsampled])\n",
    "\n",
    "# Separate features and target after resampling\n",
    "X_balanced = data_balanced.drop('strikeout_binary', axis=1)\n",
    "y_balanced = data_balanced['strikeout_binary']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_balanced_scaled = scaler.fit_transform(X_balanced)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced_scaled, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest model with class weights to handle imbalance\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, zero_division=1)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "\n",
    "accuracy_rf, precision_rf, recall_rf, roc_auc_rf"
   ],
   "id": "8525fa1a63f82230",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_rf = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'ROC AUC'],\n",
    "    'Value': [accuracy_rf, precision_rf, recall_rf, roc_auc_rf]\n",
    "}\n",
    "\n",
    "# Convert dictionary to a DataFrame\n",
    "accuracy_metrics_rf_df  = pd.DataFrame(metrics_rf)\n",
    "\n",
    "accuracy_metrics_rf_df "
   ],
   "id": "6ff78bdd6dd31630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_balanced",
   "id": "c7c4cf46857dc177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XGBoost ",
   "id": "a3ac988f2420d2df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and its parameters\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluate the tuned XGBoost model\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
    "y_pred_best_xgb_proba = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the tuned XGBoost model\n",
    "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
    "precision_best_xgb = precision_score(y_test, y_pred_best_xgb, zero_division=1)\n",
    "recall_best_xgb = recall_score(y_test, y_pred_best_xgb)\n",
    "roc_auc_best_xgb = roc_auc_score(y_test, y_pred_best_xgb_proba)\n",
    "\n",
    "best_params, accuracy_best_xgb, precision_best_xgb, recall_best_xgb, roc_auc_best_xgb"
   ],
   "id": "3248cdd1744334c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import pickle\n",
    "# \n",
    "# # Save the model\n",
    "# with open('best_xgb_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(best_xgb_model, file)"
   ],
   "id": "a04d943a8e707a90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_xgb = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'ROC AUC'],\n",
    "    'Value': [accuracy_best_xgb, precision_best_xgb, recall_best_xgb, roc_auc_best_xgb]\n",
    "}\n",
    "\n",
    "# Convert dictionary to a DataFrame\n",
    "accuracy_metrics_xgb_df  = pd.DataFrame(metrics_xgb)\n",
    "\n",
    "accuracy_metrics_xgb_df "
   ],
   "id": "ef1918ac2b1b6622",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(classification_report(y_test, y_pred_best_xgb))",
   "id": "d5f3dc21d97a4a90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate the confusion matrix for the tuned XGBoost model (best from RandomizedSearchCV)\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_best_xgb)\n",
    "\n",
    "conf_matrix_xgb"
   ],
   "id": "aaf0a90f3cc40cd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train",
   "id": "2191bdd345d98162",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_pred_best_xgb.shape",
   "id": "34b4f09750442d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_importance(best_xgb_model, importance_type='weight', ax=plt.gca())\n",
    "plt.show()"
   ],
   "id": "59db1a9112ef053d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a dictionary to map feature indices to the actual column names\n",
    "feature_names = {f\"f{i}\": col for i, col in enumerate(X_balanced.columns)}\n",
    "\n",
    "# Plot feature importance with renamed features\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plot_importance(best_xgb_model, importance_type='gain', ax=plt.gca())\n",
    "\n",
    "# Rename the feature labels\n",
    "ax.set_yticklabels([feature_names[label.get_text()] for label in ax.get_yticklabels()])\n",
    "plt.xlabel('XGBoost Feature importance')\n",
    "plt.show()"
   ],
   "id": "83901cd5a044d0a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get feature importances from the model\n",
    "importances = best_xgb_model.get_booster().get_score(importance_type='gain')\n",
    "\n",
    "# Map the feature indices to actual column names and importance values\n",
    "feature_importances = np.array([(feature_names[feature], importance) for feature, importance in importances.items()])\n",
    "feature_importances_dict = {feature_names[feature]: importance for feature, importance in importances.items()}\n",
    "\n",
    "# Display or use the feature_importances array\n",
    "feature_importances_dict"
   ],
   "id": "a52e389c9a0259ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create the SHAP explainer\n",
    "explainer = shap.Explainer(best_xgb_model, X_balanced)\n",
    "\n",
    "# Calculate SHAP values for the dataset\n",
    "shap_values = explainer(X_balanced)"
   ],
   "id": "770508a89b827656",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "shap.summary_plot(shap_values, X_balanced)",
   "id": "71d6c54f212fce5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming X_balanced is a DataFrame or numpy array\n",
    "single_instance = X_balanced.iloc[[200]]  # Replace 0 with the index of the desired observation\n",
    "\n",
    "# Calculate SHAP values for the single instance\n",
    "shap_values_single = explainer(single_instance)\n",
    "\n",
    "# Plot SHAP values for the single observation\n",
    "shap.waterfall_plot(shap_values_single[0])"
   ],
   "id": "f3eae23297d9f8fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# X_balanced\n",
    "# X_balanced.to_csv('data/X_balanced.csv')"
   ],
   "id": "b280e2a090d07cfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data_encoded[0:16198]\n",
    "# data_encoded[0:16198].to_csv('data/data_balanced.csv')"
   ],
   "id": "298be25341b3eb98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Attempting to Create a score based on Feature Importance\n",
    "- Removed pitchers that only had one pitch, because they are irrelevant to our ranking"
   ],
   "id": "4c4e25c2c0ea410c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "og_data = cleaned_data_classwise\n",
    "og_data "
   ],
   "id": "5f464236304d8c32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bruh = data_encoded.loc[:, data_encoded.columns.difference(['pitchresult_category_strike_related','pitchresult_category_foul', 'pitchresult_category_in_play', 'pitchresult_category_other', 'pitchresult_category_strikeout', 'pitchresult_category_strikeout_binary', 'movement_ratio'])]",
   "id": "1489471fe73b2d4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter the data for the desired columns\n",
    "data = bruh\n",
    "\n",
    "# Further filtering for FF pitchname and excluding 'field_out' eventtype\n",
    "data = data[(data['pitchname'] == 'FF') & (~data['eventtype'].isin(['field_out']))]\n",
    "\n",
    "# Filter to only include scenarios where pitchresult == 'C' (strikeout)\n",
    "data_strikeout = data[data['pitchresult'] == 'C']\n",
    "\n",
    "# Define the pitch characteristics for analysis\n",
    "pitch_characteristics = [\"spinrate\", \"horzbreak\", \"inducedvertbreak\", \"platelocside\", \"platelocheight\", \n",
    "                         \"relspeed\", \"average_relspeed\", \"relspeed_diff\", \"relspeed_inducedvertbreak\"]\n",
    "\n",
    "pitcher_stats = data_strikeout.groupby(\"pitcher\").filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Group by pitcher and calculate the mean and standard deviation of the pitch characteristics\n",
    "pitcher_stats = pitcher_stats.groupby(\"pitcher\")[pitch_characteristics].agg(['mean', 'std'])"
   ],
   "id": "b1e61a40a44d64de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pitcher_stats.columns",
   "id": "88e3d2df96c6c8ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pitcher_stats.reset_index(inplace=True)\n",
    "\n",
    "pitcher_stats"
   ],
   "id": "25d8557978026c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6006e5ae32a9a80f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# bruh = data_encoded.loc[:, data_encoded.columns.difference(['pitchresult_category_strike_related','pitchresult_category_foul', 'pitchresult_category_in_play', 'pitchresult_category_other', 'pitchresult_category_strikeout', 'pitchresult_category_strikeout_binary', 'movement_ratio'])]\n",
    "columns = ['pitcher'] + [col for col in bruh.columns if col != 'pitcher']\n",
    "bruh = bruh[columns]"
   ],
   "id": "c91a1f6912efc75a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reorder columns to make \"pitcher\" the first column\n",
    "bruh.drop(columns=['average_relspeed'], inplace=True)\n",
    "bruh"
   ],
   "id": "d08a640396f1e49f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating Part of the Score for Release Speed!",
   "id": "cf4eeb168b65a47c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bruh_1 = bruh\n",
    "bruh_1"
   ],
   "id": "480504887da1cd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set pitcher as the index for pitcher_stats to allow easy lookup\n",
    "pitcher_stats.set_index('pitcher', inplace=True)\n",
    "\n",
    "# Define the function to calculate the new value\n",
    "def calculate_z_score_adjusted(pitch, pitcher_stats, constant=5.74):\n",
    "    pitcher = pitch['pitcher']\n",
    "    relspeed = pitch['relspeed']\n",
    "    \n",
    "    # Get pitcher's mean and std for relspeed from pitcher_stats\n",
    "    try:\n",
    "        relspeed_mean = pitcher_stats['relspeed']['mean'][pitcher]\n",
    "        relspeed_std = pitcher_stats['relspeed']['std'][pitcher]\n",
    "        \n",
    "        # Calculate z-score and multiply by the constant\n",
    "        z_score_adjusted = ((relspeed - relspeed_mean) / relspeed_std) * constant\n",
    "        return z_score_adjusted\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the bruh dataframe\n",
    "bruh_1['relspeed_adjusted'] = bruh.apply(lambda row: calculate_z_score_adjusted(row, pitcher_stats), axis=1)"
   ],
   "id": "a5b5bc85510294ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "838c6e306c91017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bruh_1",
   "id": "ccde580e8d6631d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Set pitcher as the index for pitcher_stats to allow easy lookup\n",
    "# pitcher_stats.set_index('pitcher', inplace=True)\n",
    "# \n",
    "# # Define the function to calculate the new value\n",
    "# def calculate_z_score_adjusted(pitch, pitcher_stats, constant=6.17):\n",
    "#     pitcher = pitch['pitcher']\n",
    "#     relspeed = pitch['relspeed']\n",
    "#     \n",
    "#     # Get pitcher's mean and std for relspeed from pitcher_stats\n",
    "#     try:\n",
    "#         relspeed_mean = pitcher_stats['relspeed']['mean'][pitcher]\n",
    "#         relspeed_std = pitcher_stats['relspeed']['std'][pitcher]\n",
    "#         \n",
    "#         # Calculate z-score and multiply by the constant\n",
    "#         z_score_adjusted = ((relspeed - relspeed_mean) / relspeed_std) * constant\n",
    "#         return z_score_adjusted\n",
    "#     except KeyError:\n",
    "#         return np.nan\n",
    "# \n",
    "# # Apply the function to the bruh dataframe\n",
    "# bruh_1['relspeed_adjusted'] = bruh.apply(lambda row: calculate_z_score_adjusted(row, pitcher_stats), axis=1)\n",
    "bruh"
   ],
   "id": "e6de959f7284ff1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the function to calculate z-score adjusted values for different characteristics\n",
    "def calculate_z_score_adjusted_for_feature(pitch, pitcher_stats, feature, constant=6.17):\n",
    "    pitcher = pitch['pitcher']\n",
    "    value = pitch[feature]\n",
    "    \n",
    "    # Get pitcher's mean and std for the feature from pitcher_stats\n",
    "    try:\n",
    "        feature_mean = pitcher_stats[feature]['mean'][pitcher]\n",
    "        feature_std = pitcher_stats[feature]['std'][pitcher]\n",
    "        \n",
    "        # Calculate z-score and multiply by the constant\n",
    "        z_score_adjusted = ((value - feature_mean) / feature_std) * constant\n",
    "        return z_score_adjusted\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "# Apply these functions to the `bruh` dataframe\n",
    "bruh_1['spinrate_adjusted'] = bruh.apply(lambda row: calculate_z_score_adjusted_for_feature(row, pitcher_stats, 'spinrate', constant=3.78366), axis=1)\n",
    "bruh_1['horzbreak_adjusted'] = bruh.apply(lambda row: abs(calculate_z_score_adjusted_for_feature(row, pitcher_stats, 'horzbreak', constant =4.06374)), axis=1)\n",
    "# bruh_1['inducedvertbreak_adjusted'] = bruh.apply(lambda row: calculate_z_score_adjusted_for_feature(row, pitcher_stats, 'inducedvertbreak', constant = 3.),  axis=1)\n",
    "bruh_1['platelocside_adjusted'] = bruh.apply(lambda row: -calculate_z_score_adjusted_for_feature(row, pitcher_stats, 'platelocside', constant=29.64492), axis=1)\n",
    "bruh_1['platelocheight_adjusted'] = bruh.apply(lambda row: calculate_z_score_adjusted_for_feature(row, pitcher_stats, 'platelocheight', constant=31.36657), axis=1)\n",
    "bruh_1['relspeed_inducedvertbreak'] = bruh.apply(lambda row: calculate_z_score_adjusted_for_feature(row, pitcher_stats, 'relspeed_inducedvertbreak', constant=6.96876), axis=1)"
   ],
   "id": "e67d8721af6f9812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bruh_1",
   "id": "da9110c68f45cc20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate \"my_score\" as the row sum of the specified columns\n",
    "bruh_1['my_score'] = bruh_1[['spinrate_adjusted', 'horzbreak_adjusted', 'platelocside_adjusted', 'platelocheight_adjusted', 'relspeed_inducedvertbreak']].sum(axis=1)\n",
    "\n",
    "# Calculate the average of \"my_score\" grouped by \"pitcher\"\n",
    "average_score_by_pitcher = bruh_1.groupby('pitcher')['my_score'].mean().reset_index()\n",
    "\n",
    "# Display the result\n",
    "average_score_by_pitcher"
   ],
   "id": "3b7aebfc04228144",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "average_score_by_pitcher_sorted = average_score_by_pitcher.sort_values(by='my_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "average_score_by_pitcher_sorted"
   ],
   "id": "a8c3fc41fccb9e57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "average_score_by_pitcher[average_score_by_pitcher['pitcher'] == \"deGrom, Jacob\"]",
   "id": "44e6b3bda56a0e40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bruh_1[bruh_1['pitcher'] == \"Morton, Charlie\"]",
   "id": "e27cf1bb117c4031",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(average_score_by_pitcher['my_score'], bins=200, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('My Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of My Score Across Pitchers')\n",
    "plt.show()"
   ],
   "id": "c11cd5ab20c08449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trying to compare my score against ERA and other relevant metrics",
   "id": "f82da81d1004c81a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# !pip install pybaseball",
   "id": "76394e310d050f7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pybaseball import pitching_stats\n",
    "\n",
    "# Retrieve pitching stats for 2021 to 2023\n",
    "data = pitching_stats(2021, 2023)\n",
    "# Filter for desired columns\n",
    "era_data = data[['Season', 'Name', 'Team', 'ERA']]"
   ],
   "id": "279c4e7936ed5bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "era_data",
   "id": "fd135f18c3f0a880",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculating the overall average ERA for each pitcher across all seasons\n",
    "overall_average_era = era_data.groupby('Name')['ERA'].mean().reset_index()\n",
    "\n",
    "overall_average_era"
   ],
   "id": "7c765c094da2d3c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Adjusting the names in average_score_by_pitcher to match the format in overall_average_era\n",
    "\n",
    "# Function to reformat \"Lastname, Firstname\" to \"Firstname Lastname\"\n",
    "def reformat_name(name):\n",
    "    last, first = name.split(', ')\n",
    "    return f\"{first} {last}\"\n",
    "\n",
    "# Applying the reformatting function\n",
    "average_score_by_pitcher['Name'] = average_score_by_pitcher['pitcher'].apply(reformat_name)\n",
    "\n",
    "# Merging the dataframes on the reformatted name column\n",
    "merged_data = overall_average_era.merge(average_score_by_pitcher, on=\"Name\")\n",
    "\n",
    "# Plotting the ERA vs. my_score for each pitcher\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged_data['ERA'], merged_data['my_score'], color='blue', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Average ERA\")\n",
    "plt.ylabel(\"Average My Score\")\n",
    "plt.title(\"Comparison of Average ERA and Average My Score by Pitcher\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ],
   "id": "23c5df56a757881d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_data",
   "id": "3148bc7011f49b1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the Pearson correlation coefficient between ERA and my_score\n",
    "correlation = merged_data['ERA'].corr(merged_data['my_score'])\n",
    "print(\"Correlation between ERA and my_score:\", correlation)"
   ],
   "id": "14ceb86412580f1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter data to include only rows where my_score is between -20 and 20\n",
    "subset_data = merged_data[(merged_data['my_score'] >= 50) & (merged_data['my_score'] <= 90)]\n",
    "\n",
    "# Calculate the correlation for the filtered subset\n",
    "subset_correlation = subset_data['ERA'].corr(subset_data['my_score'])\n",
    "print(\"Correlation between ERA and my_score in [-20, 20]:\", subset_correlation)\n",
    "\n",
    "# Calculate the correlation for the full dataset for comparison\n",
    "full_correlation = merged_data['ERA'].corr(merged_data['my_score'])\n",
    "print(\"Correlation between ERA and my_score for all data:\", full_correlation)\n"
   ],
   "id": "8f26042763e07e84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plotting the ERA vs. my_score for the filtered range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(subset_data['ERA'], subset_data['my_score'], color='green', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Average ERA\")\n",
    "plt.ylabel(\"Average My Score\")\n",
    "plt.title(\"Comparison of Average ERA and My Score by Pitcher (My Score between -20 and 20)\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ],
   "id": "80b986f3204e0dac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
